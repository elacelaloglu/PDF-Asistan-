import streamlit as st
import os
import tempfile
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# --- AYARLAR ---
# GROQ ANAHTARINI BURAYA YAPIÅTIR
GROQ_API_KEY = "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"

st.set_page_config(page_title="PDF AsistanÄ±", layout="wide")
st.title("â˜ï¸ CanlÄ± PDF AsistanÄ±")
st.markdown("Sol taraftan bir PDF yÃ¼kleyin ve hemen soru sormaya baÅŸlayÄ±n!")

# Yan MenÃ¼ - Dosya YÃ¼kleme
with st.sidebar:
    st.header("ğŸ“‚ Dosya YÃ¼kle")
    uploaded_file = st.file_uploader("Bir PDF dosyasÄ± seÃ§in", type="pdf")
    st.info("Motor: Llama 3.3 (Groq)")
    st.warning("Not: Site yenilendiÄŸinde veriler sÄ±fÄ±rlanÄ±r.")

# VeritabanÄ± HazÄ±rlama Fonksiyonu (Bulut Ä°Ã§in Ã–zel)
@st.cache_resource
def pdf_islee(file):
    # GeÃ§ici bir klasÃ¶r oluÅŸturup dosyayÄ± oraya kaydediyoruz
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(file.read())
        tmp_path = tmp_file.name

    # PDF'i Oku ve ParÃ§ala
    loader = PyPDFLoader(tmp_path)
    docs = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)

    # VeritabanÄ±na GÃ¶m (HafÄ±zada tutuyoruz, klasÃ¶re yazmÄ±yoruz)
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    db = Chroma.from_documents(documents=splits, embedding=embedding_model)
    
    # GeÃ§ici dosyayÄ± temizle
    os.remove(tmp_path)
    return db

# --- ANA AKIÅ ---

if uploaded_file is None:
    # Dosya yoksa uyarÄ± gÃ¶ster
    st.info("ğŸ‘ˆ LÃ¼tfen sol menÃ¼den bir PDF dosyasÄ± yÃ¼kleyin.")
    st.image("https://cdn-icons-png.flaticon.com/512/337/337946.png", width=100) # Ok iÅŸareti

else:
    # Dosya varsa iÅŸle
    with st.spinner("PDF analiz ediliyor... (Bu iÅŸlem sadece bir kez yapÄ±lÄ±r)"):
        try:
            db = pdf_islee(uploaded_file)
            st.success("âœ… PDF yÃ¼klendi! Sorunuzu sorabilirsiniz.")
            
            # Soru Kutusu
            soru = st.text_input("Sorunuzu yazÄ±n:", placeholder="Ã–rn: Bu projenin amacÄ± ne?")
            
            if st.button("GÃ¶nder ğŸš€") and soru:
                
                # Yapay Zeka AyarÄ±
                llm = ChatGroq(temperature=0, model_name="llama-3.3-70b-versatile", api_key=GROQ_API_KEY)
                
                with st.spinner("Cevap hazÄ±rlanÄ±yor..."):
                    # Benzerlik AramasÄ±
                    sonuclar = db.similarity_search(soru, k=4)
                    context = "\n\n".join([doc.page_content for doc in sonuclar])
                    
                    # Cevap Ãœretme
                    prompt = f"""
                    AÅŸaÄŸÄ±daki DOKÃœMAN BÄ°LGÄ°SÄ°'ne gÃ¶re SORU'yu TÃ¼rkÃ§e cevapla.
                    Bilgi yoksa "DokÃ¼manda bulamadÄ±m" de.
                    
                    DOKÃœMAN BÄ°LGÄ°SÄ°:
                    {context}
                    
                    SORU:
                    {soru}
                    """
                    cevap = llm.invoke(prompt)
                    
                    st.write("### ğŸ¤– Cevap:")
                    st.write(cevap.content)
                    
                    with st.expander("Kaynaklar"):
                         for i, b in enumerate(sonuclar):
                            st.caption(f"**ParÃ§a {i+1}:** {b.page_content[:200]}...")

        except Exception as e:
            st.error(f"Bir hata oluÅŸtu: {e}")