import streamlit as st
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq

# --- AYARLAR ---
# GROQ ANAHTARINI BURAYA YAPIÅTIR (gsk_... ile baÅŸlar)
GROQ_API_KEY = "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"

# Sayfa AyarlarÄ±
st.set_page_config(page_title="SÃ¼per HÄ±zlÄ± Asistan", layout="wide")
st.title("âš¡ SÃ¼per HÄ±zlÄ± DokÃ¼man AsistanÄ±")

# Yan MenÃ¼
with st.sidebar:
    st.success("Motor: Llama 3.3 (Groq)")
    st.info("DÃ¼nyanÄ±n en yeni ve hÄ±zlÄ± aÃ§Ä±k kaynak modeli.")

# 1. VeritabanÄ±nÄ± YÃ¼kle
@st.cache_resource
def veritabani_yukle():
    try:
        embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        db = Chroma(persist_directory="./chroma_db", embedding_function=embedding_model)
        return db
    except Exception as e:
        return None

db = veritabani_yukle()

if not db:
    st.error("VeritabanÄ± bulunamadÄ±.")
    st.stop()

# 2. Yapay ZekayÄ± BaÅŸlat (GÃœNCEL MODEL)
try:
    llm = ChatGroq(
        temperature=0, 
        # !!! Ä°ÅTE DEÄÄ°ÅÄ°KLÄ°K BURADA !!!
        # Eski model yerine en yeni ve en gÃ¼Ã§lÃ¼ modeli yazdÄ±k.
        model_name="llama-3.3-70b-versatile", 
        api_key=GROQ_API_KEY
    )
except Exception as e:
    st.error(f"API AnahtarÄ± hatasÄ±: {e}")
    st.stop()

# 3. ArayÃ¼z
soru = st.text_input("Sorunuzu yazÄ±n:", placeholder="Ã–rn: Proje yÃ¼rÃ¼tÃ¼cÃ¼sÃ¼ kim?")

if st.button("Soruyu GÃ¶nder ğŸš€"):
    if not soru:
        st.warning("LÃ¼tfen bir soru yazÄ±n.")
    else:
        with st.spinner("DokÃ¼manlar taranÄ±yor..."):
            sonuclar = db.similarity_search(soru, k=4)
            bilgi_havuzu = ""
            for belge in sonuclar:
                bilgi_havuzu += belge.page_content + "\n\n"
        
        with st.spinner("Llama 3.3 dÃ¼ÅŸÃ¼nÃ¼yor..."):
            try:
                prompt = f"""
                AÅŸaÄŸÄ±daki BÄ°LGÄ°'ye gÃ¶re SORU'yu TÃ¼rkÃ§e cevapla.
                Bilgi iÃ§inde cevap yoksa "DokÃ¼manlarda bulamadÄ±m" de.
                
                BÄ°LGÄ°:
                {bilgi_havuzu}
                
                SORU:
                {soru}
                """
                
                cevap = llm.invoke(prompt)
                
                st.success("âœ… Cevap:")
                st.write(cevap.content)
                
                with st.expander("Kaynak Paragraflar"):
                    for i, b in enumerate(sonuclar):
                        st.markdown(f"**ParÃ§a {i+1}:**")
                        st.caption(b.page_content)
                        st.divider()

            except Exception as e:
                st.error(f"Hata oluÅŸtu: {e}")