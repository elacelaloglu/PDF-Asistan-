import streamlit as st
import os
import tempfile
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# --- AYARLAR ---
# GROQ ANAHTARINI BURAYA YAPIÅTIR
GROQ_API_KEY = "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"

# Sayfa AyarlarÄ±
st.set_page_config(page_title="Pro Asistan", layout="wide")
st.title("ğŸ§  Profesyonel DokÃ¼man AsistanÄ±")
st.markdown("Birden fazla PDF yÃ¼kleyin, sohbet edin ve detaylÄ± analizler alÄ±n.")

# --- SESSION STATE (HAFIZA) ---
# Sohbet geÃ§miÅŸini burada tutacaÄŸÄ±z
if "messages" not in st.session_state:
    st.session_state.messages = []

if "db" not in st.session_state:
    st.session_state.db = None

# --- YAN MENÃœ (DOSYA YÃœKLEME) ---
with st.sidebar:
    st.header("ğŸ“‚ DokÃ¼man YÃ¶netimi")
    # accept_multiple_files=True ile Ã§oklu seÃ§im aÃ§Ä±ldÄ±
    uploaded_files = st.file_uploader("PDF DosyalarÄ±nÄ± SeÃ§in", type="pdf", accept_multiple_files=True)
    
    process_btn = st.button("DokÃ¼manlarÄ± Analiz Et âš¡")
    
    st.divider()
    st.info("Model: Llama 3.3 (Groq)")
    if st.button("Sohbeti Temizle ğŸ—‘ï¸"):
        st.session_state.messages = []
        st.rerun()

# --- FONKSÄ°YONLAR ---
def veritabani_olustur(files):
    documents = []
    
    # Ä°lerleme Ã§ubuÄŸu
    progress_bar = st.progress(0)
    
    for i, file in enumerate(files):
        # Her dosyayÄ± geÃ§ici olarak kaydet
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(file.read())
            tmp_path = tmp_file.name

        # Oku
        loader = PyPDFLoader(tmp_path)
        docs = loader.load()
        documents.extend(docs) # Listeye ekle
        
        # DosyayÄ± sil
        os.remove(tmp_path)
        
        # Ä°lerlemeyi gÃ¼ncelle
        progress_bar.progress((i + 1) / len(files))

    # ParÃ§ala
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(documents)

    # VeritabanÄ±na GÃ¶m
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    db = Chroma.from_documents(documents=splits, embedding=embedding_model)
    
    progress_bar.empty() # Ã‡ubuÄŸu temizle
    return db

# --- Ä°ÅLEM AKIÅI ---

# 1. DokÃ¼manlarÄ± Ä°ÅŸle (Butona basÄ±lÄ±nca)
if process_btn and uploaded_files:
    with st.spinner("DokÃ¼manlar birleÅŸtiriliyor ve yapay zeka tarafÄ±ndan okunuyor..."):
        try:
            st.session_state.db = veritabani_olustur(uploaded_files)
            st.success(f"âœ… Toplam {len(uploaded_files)} dosya baÅŸarÄ±yla iÅŸlendi!")
            st.session_state.messages = [] # Yeni dosya gelince sohbeti sÄ±fÄ±rla
        except Exception as e:
            st.error(f"Hata: {e}")

# 2. Sohbet GeÃ§miÅŸini Ekrana Yaz
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 3. KullanÄ±cÄ±dan Yeni Soru Al (Chat Input)
if prompt := st.chat_input("Sorunuzu buraya yazÄ±n..."):
    
    # VeritabanÄ± kontrolÃ¼
    if st.session_state.db is None:
        st.warning("LÃ¼tfen Ã¶nce sol taraftan PDF yÃ¼kleyip 'Analiz Et' butonuna basÄ±n.")
    else:
        # KullanÄ±cÄ± mesajÄ±nÄ± ekrana ve hafÄ±zaya ekle
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Cevap Ãœretme
        with st.chat_message("assistant"):
            with st.spinner("DÃ¼ÅŸÃ¼nÃ¼yor..."):
                try:
                    # RAG - Arama
                    db = st.session_state.db
                    sonuclar = db.similarity_search(prompt, k=5)
                    context = "\n\n".join([doc.page_content for doc in sonuclar])
                    
                    # Sohbet GeÃ§miÅŸini Metne Ã‡evir (HafÄ±za)
                    gecmis_sohbet = ""
                    for msg in st.session_state.messages[-6:]: # Son 6 mesajÄ± hatÄ±rla (HÄ±z iÃ§in)
                        gecmis_sohbet += f"{msg['role']}: {msg['content']}\n"

                    # GeliÅŸmiÅŸ Prompt (DetaylÄ± Cevap Ä°Ã§in)
                    system_prompt = f"""
                    Sen uzman bir kurumsal asistansÄ±n. GÃ¶revin verilen dokÃ¼manlara dayanarak detaylÄ±, profesyonel ve aÃ§Ä±klayÄ±cÄ± cevaplar vermektir.
                    
                    KURALLAR:
                    1. CevaplarÄ±n doyurucu ve uzun olsun. Maddeler halinde aÃ§Ä±klama yapmayÄ± tercih et.
                    2. Sohbet geÃ§miÅŸini dikkate al. KullanÄ±cÄ± "O kim?" derse, geÃ§miÅŸten kimden bahsettiÄŸini anla.
                    3. Bilgiyi sadece aÅŸaÄŸÄ±daki DOKÃœMAN iÃ§eriÄŸinden al. Uydurma yapma.
                    
                    SOHBET GEÃ‡MÄ°ÅÄ°:
                    {gecmis_sohbet}
                    
                    DOKÃœMAN BÄ°LGÄ°SÄ°:
                    {context}
                    
                    KULLANICI SORUSU:
                    {prompt}
                    """
                    
                    # Groq'a GÃ¶nder
                    llm = ChatGroq(temperature=0.3, model_name="llama-3.3-70b-versatile", api_key=GROQ_API_KEY)
                    response = llm.invoke(system_prompt)
                    cevap = response.content
                    
                    # CevabÄ± Yaz
                    st.markdown(cevap)
                    
                    # HafÄ±zaya Kaydet
                    st.session_state.messages.append({"role": "assistant", "content": cevap})
                    
                    # KaynaklarÄ± gÃ¶ster (Expander iÃ§inde)
                    with st.expander("Referans Kaynaklar"):
                        for i, doc in enumerate(sonuclar):
                            st.caption(f"**Kaynak {i+1}:** {doc.page_content[:200]}...")

                except Exception as e:
                    st.error(f"Hata oluÅŸtu: {e}")